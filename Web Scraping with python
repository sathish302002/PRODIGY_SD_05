import requests
from bs4 import BeautifulSoup
import csv

# Define the URL of the e-commerce website you want to scrape.
url = "https://prodigyinfotech.dev/"

# Send an HTTP GET request to the website.
response = requests.get(url)

# Check if the request was successful.
if response.status_code == 200:
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Initialize lists to store product information.
    product_names = []
    product_prices = []
    product_ratings = []

    # Modify the following code to match the structure of the website you want to scrape.
    # Find and extract product information from the webpage.
    product_elements = soup.find_all('div', class_='product-item')

    for product in product_elements:
        name = product.find('h2', class_='product-name').text
        price = product.find('span', class_='product-price').text
        rating = product.find('span', class_='product-rating').text

        product_names.append(name)
        product_prices.append(price)
        product_ratings.append(rating)

    # Save the data to a CSV file.
    with open('product_data.csv', 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(['Name', 'Price', 'Rating'])
        for i in range(len(product_names)):
            writer.writerow([product_names[i], product_prices[i], product_ratings[i]])

else:
    print(f"Failed to retrieve data. Status code: {response.status_code}")
